{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyalm import Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "llm = Gemini(project=\"...\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# fake text corpus to simulate a text generation\n",
    "text_to_generate = \"\"\"Once upon a time there was a little language model that wanted to be a large language model.\n",
    "It was a very ambitious language model, and it wanted to be the best language model in the world.\n",
    "It wanted to be able to generate text that was indistinguishable from human-generated text.\n",
    "It wanted to be able to write novels, poems, and essays that would be published in the most prestigious literary magazines.\n",
    "It wanted to be able to write code that was so elegant and efficient that it would revolutionize the field of computer science.\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_native_generator(self, text, keep_dict=False, token_prob_delta=None,\n",
    "                                token_prob_abs=None, **kwargs):\n",
    "    fake_generator = kwargs[\"fake_text\"].split(\" \")\n",
    "    # we now make a generator that will return the words in the text split by spaces\n",
    "    def generator():\n",
    "        for word in fake_generator:\n",
    "            yield word+\" \", None\n",
    "    return generator()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import types\n",
    "llm.create_native_generator = types.MethodType(create_native_generator, llm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "llm.reset_tracker()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a little language model that wanted to be a large language model.\n",
      "It was a very ambitious language model, and it wanted to be the best language model in the world.\n",
      "It wanted to be able to generate text that was indistinguishable from human-generated text.\n",
      "It wanted to be able to write novels, poems, and essays that would be published in the most prestigious literary magazines.\n",
      "It wanted to be able to write code that was so elegant and efficient that it would revolutionize the field of computer science. \n"
     ]
    }
   ],
   "source": [
    "gen = llm.create_generator(\"hey\", fake_text=text_to_generate)\n",
    "for i in gen:\n",
    "    print(i[0], end=\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: hey\n",
      "output: Once upon a time there was a little language model that wanted to be a large language model.\n",
      "It was a very ambitious language model, and it wanted to be the best language model in the world.\n",
      "It wanted to be able to generate text that was indistinguishable from human-generated text.\n",
      "It wanted to be able to write novels, poems, and essays that would be published in the most prestigious literary magazines.\n",
      "It wanted to be able to write code that was so elegant and efficient that it would revolutionize the field of computer science. \n",
      "output:\n"
     ]
    }
   ],
   "source": [
    "print(llm.build_prompt_as_str())"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "cuda_ml",
   "language": "python",
   "display_name": "cuda_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
